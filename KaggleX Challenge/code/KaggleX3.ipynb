{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KaggleX Challenge Notebook\n",
    "\n",
    "This notebook holds the code for the KaggleX Challenge. The challenge is to predict the price of used cars based on the given features. The dataset is taken from the Kaggle competition [here](https://www.kaggle.com/competitions/kagglex-cohort4/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's done in this notebook:\n",
    "- Extracted data from engine feature\n",
    "- Scaled numerical features and encoded categorical features\n",
    "- Splited train data\n",
    "- Trained a Random Forest and a Gradient Boosting model\n",
    "- Evaluated the models using MAE and MSE\n",
    "- Predicted the price of the test data using Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 Lariat</td>\n",
       "      <td>2018</td>\n",
       "      <td>74349</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>10-Speed A/T</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id brand         model  model_year  milage fuel_type  \\\n",
       "0   0  Ford  F-150 Lariat        2018   74349  Gasoline   \n",
       "\n",
       "                                          engine  transmission ext_col  \\\n",
       "0  375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel  10-Speed A/T    Blue   \n",
       "\n",
       "  int_col       accident clean_title  price  \n",
       "0    Gray  None reported         Yes  11000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RANDOM_SEED = 6\n",
    "\n",
    "# Load the training data\n",
    "train_data_path = '../data/train.csv'\n",
    "test_data_path = '../data/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "train_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54273, 2324),\n",
       " 0    11000\n",
       " 1     8250\n",
       " 2    15000\n",
       " 3    63500\n",
       " 4     7850\n",
       " Name: price, dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import re\n",
    "\n",
    "# Refine the feature extraction function\n",
    "def extract_engine_features(df):\n",
    "    # Extract horsepower with error handling for non-matching patterns\n",
    "    df['horsepower'] = df['engine'].apply(\n",
    "        lambda x: int(re.search(r'(\\d+)\\.0HP', x).group(1)) if pd.notnull(x) and re.search(r'(\\d+)\\.0HP', x) else 0\n",
    "    )\n",
    "    # Extract number of cylinders with error handling for non-matching patterns\n",
    "    df['cylinders'] = df['engine'].apply(\n",
    "        lambda x: int(re.search(r'(\\d+) Cylinder', x).group(1)) if pd.notnull(x) and re.search(r'(\\d+) Cylinder', x) else 0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Apply the feature extraction\n",
    "train_df = extract_engine_features(train_df)\n",
    "\n",
    "# Drop the original engine column and 'id' column\n",
    "train_df = train_df.drop(columns=['engine', 'id'])\n",
    "\n",
    "# Preprocess the categorical columns using one-hot encoding and scale the numerical columns\n",
    "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "numerical_features = ['model_year', 'milage', 'horsepower', 'cylinders']\n",
    "\n",
    "# Define the preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessing steps\n",
    "X_train = train_df.drop(columns=['price'])\n",
    "y_train = train_df['price']\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Display the shape of the processed training data and the first few rows of the target variable\n",
    "X_train_processed.shape, y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_processed, y_train, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "model_rf.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "model_gb.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for choosing the best model\n",
    "y_pred_rf = model_rf.predict(X_val_split)\n",
    "y_pred_gb = model_gb.predict(X_val_split)\n",
    "mse_rf = mean_squared_error(y_val_split, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_val_split, y_pred_rf)\n",
    "mse_gb = mean_squared_error(y_val_split, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_val_split, y_pred_gb)\n",
    "print(f'Random Forest - Validation MSE: {mse_rf:.2f}, MAE: {mae_rf:.2f}')\n",
    "print(f'Gradient Boosting - Validation MSE: {mse_gb:.2f}, MAE: {mae_gb:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Gradient Boosting model for prediction trained on the entire training data\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "model_gb.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Load the model to disk\n",
    "import pickle\n",
    "\n",
    "model_path = '../models/KaggleX3.pkl'\n",
    "\n",
    "# Save\n",
    "# with open(model_path, 'wb') as file:\n",
    "#     pickle.dump(model_gb, file)\n",
    "\n",
    "# Load\n",
    "with open(model_path, 'rb') as file:\n",
    "    model_gb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the feature extraction to the test data\n",
    "test_df = extract_engine_features(test_df)\n",
    "test_df = test_df.drop(columns=['engine', 'id'])\n",
    "X_test = preprocessor.transform(test_df)\n",
    "y_test_pred = model_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the submission file\n",
    "sub_template = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sub_template.copy()\n",
    "submission['price'] = y_test_pred\n",
    "submission.to_csv('../submissions/submission3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
